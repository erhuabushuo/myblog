Title: 数据挖掘指南：三十二、朴素贝叶斯的效果要比近邻算法好吗？
Date: 2016-09-21 11:55
Category: Data Mining

朴素贝叶斯的效果要比近邻算法好吗？

## 回顾

之前我们对近邻算法做了统计：

![](http://i4.piimg.com/1949/1bf11cface4e9ad0.png)

以下是贝叶斯算法的结果：

![](http://i4.piimg.com/1949/58942b35275ddcf7.png)

哇，看来贝叶斯的效果要比近邻算法来得好呢！
kNN算法中，k=3时的Kappa指标是0.35415，效果一般。那朴素贝叶斯的Kappa指标是多少呢？

![](http://i4.piimg.com/1949/4a6498a9945a5e2b.png)

贝叶斯的Kappa指标是0.4875，符合期望。

因此在这个例子中，朴素贝叶斯的效果要比近邻算法好。

贝叶斯方法的优点：

* 实现简单（只需计数即可）
* 需要的训练集较少
* 运算效率高

贝叶斯方法的主要缺点是无法学习特征之间的相互影响。比如我喜欢奶酪，也喜欢米饭，但是不喜欢两者一起吃。

kNN算法的优点：

* 实现也比较简单
* 不需要按特定形式准备数据
* 需要大量内存保存训练集数据

当我们的训练集较大时，kNN算法是一个不错的选择。这个算法的用途很广，包括推荐系统、蛋白质分析、图片分类等。

## 解答

我们之所以能将多个概率进行相乘是因为这些概率都是具有独立性的。比如说，有一个游戏是同时抛硬币和掷骰子，骰子的点数并不依赖于硬币是正面还是反面，所以在计算联合概率时可以直接相乘。如果我们要计算同时抛出正面（heads）以及掷出6点的概率：

![](http://i4.piimg.com/1949/11952239ee7cf074.png)

再比如我们有一副扑克牌，保留所有黑色牌（26张），以及红色牌中的人头牌（6张），一共32张。那么，选出一张人头牌（facecard）的概率就是：

![](http://i4.piimg.com/1949/e480882dc48fa795.png)

选出红色牌（red）的概率是：

![](http://i4.piimg.com/1949/2d925c35c5df673c.png)

那么，选出一张即是红色牌又是人头牌的概率是多少呢？直觉告诉我们不能这样计算：

![](http://i4.piimg.com/1949/766be78235ee9bff.png)

因为红色牌的概率是0.1875，但这张红色牌100%是人头牌，所以红色人头牌的概率应该是0.1875。

这里不能做乘法就是因为这两个事件不是互相独立的，在选择红色牌时，人头牌的概率就变了，反之亦然。

在现实数据挖掘场景中，这种特征变量之间不独立的情况还是很多的。

* 运动员例子中，身高和体重不是互相独立的，因为高的人体重也会较高。
* 地区邮编、收入、年龄，这些特征也不完全独立，一些地区的房屋都很昂贵，一些地区则只有房车：加州帕罗奥图大多是20岁的年轻人，而亚利桑那州则多是退休人员。
* 在音乐基因工程中，很多特征也是不独立的，如果音乐中有很多变音吉他，那小提琴的概率就降低了。
* 血液检验的结果中，T4和TSH这两个指标通常是呈反比的。

再从你身边找找例子，比如你的车，它的各种特征之间有相关性吗？一部电影呢？亚马逊上的购买记录又如何？

所以，在使用贝叶斯方法时，我们需要互相独立的特征，但现实生活中很难找到这样的应用，因此我们只能假设他们是独立的了！我们完全忽略了这个问题，因此才称为“朴素的”（天真的）贝叶斯方法。不过事实证明朴素贝叶斯的效果还是很不错的。

